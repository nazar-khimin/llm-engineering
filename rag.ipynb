{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Practice 2: Retrieval-Augmented Generation (RAG) with Azure OpenAI and FAISS\n",
    "### Plan:\n",
    "- initialize embeddings and llm\n",
    "- create vectors for individual queries, compare distances/similarities\n",
    "- load dataset\n",
    "- split into chunks, see documents created\n",
    "- create vector store from chunks\n",
    "- retrieve relevant chunks for a query manually\n",
    "- generate answer with LLM manually\n",
    "- create retriever + generation chain\n",
    "- test end-to-end"
   ],
   "id": "f0df1a509bdb99c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:15:31.397807Z",
     "start_time": "2025-11-13T10:15:31.384715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import AzureOpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv()\n",
    "AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT = os.getenv(\"EMBEDDING_DEPLOYMENT_NAME\")\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY missing\""
   ],
   "id": "35a2262026acd5ba",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Initialize embeddings model, LLM, and similarity functions",
   "id": "909b9527500ef774"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:15:32.704841Z",
     "start_time": "2025-11-13T10:15:32.337241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    deployment=AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT,\n",
    "    base_url=None,\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    ")\n",
    "\n",
    "# (Vector store will be created after chunks are generated)"
   ],
   "id": "7ec7977e98f9e389",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store ready.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:15:32.797458Z",
     "start_time": "2025-11-13T10:15:32.791925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4.1\", temperature=0.0)\n",
    "print(\"LLM ready.\")"
   ],
   "id": "423bfe7d43a346e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM ready.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:15:33.293076Z",
     "start_time": "2025-11-13T10:15:33.285653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def l2_distance(a, b):\n",
    "    return np.linalg.norm(np.array(a) - np.array(b))\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ],
   "id": "e2e6445bd9f63c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Task 1: Manually embedd queries and compare distances/similarities",
   "id": "18ef8a80308e663a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "vector1 = embeddings.embed_query(...)\n",
    "vector2 = embeddings.embed_query(...)\n",
    "vector3 = embeddings.embed_query(...)\n",
    "\n",
    "print(\"L2 distance (similar things):\", l2_distance(vector1, vector2))\n",
    "print(\"Cosine similarity (similar things):\", cosine_similarity(vector1, vector2))\n",
    "\n",
    "print(\"L2 distance (different things):\", l2_distance(vector1, vector3))\n",
    "print(\"Cosine similarity (different things):\", cosine_similarity(vector1, vector3))"
   ],
   "id": "1f8674f107992674",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cf38d612dca16e5d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prepare dataset: load and split into chunks",
   "id": "23ec97046333e1c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c9bdbb5e1cd91f83"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# New cell: fetch 1000 random Wikipedia articles (kept separate; not used below unless you swap in wiki_documents)",
   "id": "73da65e8dd2c8924"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:46:03.503388Z",
     "start_time": "2025-11-13T10:45:18.940200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests, time\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "API_URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "UA = \"Mozilla/5.0\"\n",
    "\n",
    "def fetch_random_wikipedia_articles(n=1000, per_call=20, batch_size=50, sleep=0.2):\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\"User-Agent\": UA})\n",
    "\n",
    "    titles = []\n",
    "    remaining = n\n",
    "    while remaining > 0:\n",
    "        chunk = min(per_call, remaining)\n",
    "        r = session.get(\n",
    "            API_URL,\n",
    "            params={\n",
    "                \"action\": \"query\",\n",
    "                \"list\": \"random\",\n",
    "                \"rnnamespace\": 0,\n",
    "                \"rnlimit\": chunk,\n",
    "                \"rnfilterredir\": \"nonredirects\",  # << exclude redirects\n",
    "                \"format\": \"json\",\n",
    "            },\n",
    "            timeout=30,\n",
    "        )\n",
    "        r.raise_for_status()\n",
    "        pages = r.json().get(\"query\", {}).get(\"random\", [])\n",
    "        titles.extend(p[\"title\"] for p in pages if \"title\" in p)\n",
    "        remaining -= len(pages)\n",
    "        time.sleep(sleep)\n",
    "\n",
    "    documents_out = []\n",
    "    for i in range(0, len(titles), batch_size):\n",
    "        batch = titles[i:i+batch_size]\n",
    "        resp = session.get(\n",
    "            API_URL,\n",
    "            params={\n",
    "                \"action\": \"query\",\n",
    "                \"prop\": \"extracts\",\n",
    "                \"explaintext\": 1,\n",
    "                \"exintro\": 1,              # keep it small; optional\n",
    "                \"exlimit\": len(batch),\n",
    "                \"titles\": \"|\".join(batch),\n",
    "                \"redirects\": 1,            # << follow redirects if any\n",
    "                \"format\": \"json\",\n",
    "            },\n",
    "            timeout=60,\n",
    "        )\n",
    "        resp.raise_for_status()\n",
    "        pages_dict = resp.json().get(\"query\", {}).get(\"pages\", {})\n",
    "        for page in pages_dict.values():\n",
    "            text = (page.get(\"extract\") or \"\").strip()\n",
    "            if not text:\n",
    "                continue\n",
    "            page_id = page.get(\"pageid\")\n",
    "            documents_out.append(\n",
    "                Document(\n",
    "                    page_content=text,\n",
    "                    metadata={\n",
    "                        \"title\": page.get(\"title\"),\n",
    "                        \"pageid\": page_id,\n",
    "                        \"article_url\": f\"https://en.wikipedia.org/?curid={page_id}\" if page_id else None,\n",
    "                    },\n",
    "                )\n",
    "            )\n",
    "        time.sleep(sleep)\n",
    "\n",
    "    return documents_out\n",
    "\n",
    "\n",
    "print(\"Fetching 1000 random Wikipedia articles \")\n",
    "\n",
    "wiki_documents = fetch_random_wikipedia_articles()\n",
    "print(f\"Retrieved {len(wiki_documents)} articles with non-empty text.\")"
   ],
   "id": "88ad80c4889e2d01",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 1000 random Wikipedia articles \n",
      "Retrieved 400 articles with non-empty text.\n",
      "Fetching 1000 random Wikipedia articles...\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:49:39.738521Z",
     "start_time": "2025-11-13T10:49:39.729456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Showing 2 examples from the first 400 retrieved Wikipedia articles:\\n\")\n",
    "for i, doc in enumerate(wiki_documents[:3]):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"Title: {doc.metadata.get('title')}\")\n",
    "    print(f\"Text (excerpt): {doc.page_content[:500]}\")\n",
    "    print(f\"Metadata: {doc.metadata}\\n\")"
   ],
   "id": "b2a7b7c0f0c86f96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing 2 examples from the first 400 retrieved Wikipedia articles:\n",
      "\n",
      "Example 1:\n",
      "Title: Belonocnema kinseyi\n",
      "Text (excerpt): Belonocnema kinseyi is a species of gall wasp that forms galls on Quercus virginiana and Quercus fusiformis. There are both asexual and sexual generations. The asexual generation forms galls on the underside of leaves whereas the sexual generation form galls on the roots. It can be found in the United States, where it is known from Louisiana, Mississippi, Oklahoma and Texas. It, along with the other described Belonocnema species, have been used to study speciation.\n",
      "Metadata: {'title': 'Belonocnema kinseyi', 'pageid': 76804159, 'article_url': 'https://en.wikipedia.org/?curid=76804159'}\n",
      "\n",
      "Example 2:\n",
      "Title: Botanist (disambiguation)\n",
      "Text (excerpt): A botanist is a scientist specialized in botany.\n",
      "It may also mean:\n",
      "\n",
      "Botanist (liquor)\n",
      "Botanist (band)\n",
      "Metadata: {'title': 'Botanist (disambiguation)', 'pageid': 74197645, 'article_url': 'https://en.wikipedia.org/?curid=74197645'}\n",
      "\n",
      "Example 3:\n",
      "Title: Buzzy Boop\n",
      "Text (excerpt): Buzzy Boop (originally untitled) is a 1938 Fleischer Studios animated short film in the Max Fleischer/Betty Boop Cartoon featuring Betty Boop and her young tomboy cousin Buzzy Boop.\n",
      "Metadata: {'title': 'Buzzy Boop', 'pageid': 27960737, 'article_url': 'https://en.wikipedia.org/?curid=27960737'}\n",
      "\n",
      "Example 4:\n",
      "Title: C-20 Gulfstream\n",
      "Text (excerpt): The United States military has designated two aircraft versions as the C-20 Gulfstream:\n",
      "\n",
      "The Gulfstream III, designated the C-20A/B/C/D/E in military service.\n",
      "The Gulfstream IV, designated the C-20F/G/H in military service.\n",
      "Metadata: {'title': 'C-20 Gulfstream', 'pageid': 9057331, 'article_url': 'https://en.wikipedia.org/?curid=9057331'}\n",
      "\n",
      "Example 5:\n",
      "Title: Cascata (footballer)\n",
      "Text (excerpt): AntÃ´nio Givanildo da Silva Santos (born 2 June 1982), better known as Cascata, is a Brazilian former professional footballer who played as an attacking midfielder.\n",
      "Metadata: {'title': 'Cascata (footballer)', 'pageid': 76402011, 'article_url': 'https://en.wikipedia.org/?curid=76402011'}\n",
      "\n",
      "Example 6:\n",
      "Title: Ceresville, Maryland\n",
      "Text (excerpt): Ceresville is an unincorporated community in Frederick County, Maryland.\n",
      "Metadata: {'title': 'Ceresville, Maryland', 'pageid': 21081796, 'article_url': 'https://en.wikipedia.org/?curid=21081796'}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initialize text splitter",
   "id": "a21f9ad5e45f59b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:55:22.952195Z",
     "start_time": "2025-11-13T10:55:22.909898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "chunks = text_splitter.split_documents(wiki_documents)\n",
    "print(f\"Created {len(chunks)} chunks\")\n",
    "\n",
    "print(f\"Original number of documents: {len(wiki_documents)}\")\n",
    "print(f\"Resulting number of chunks: {len(chunks)}\")\n",
    "\n",
    "print(\"Showing 2 example chunks:\\n\")\n",
    "for i, chunk in enumerate(chunks[:2]):\n",
    "    print(f\"--- Chunk {i} ---\\n {chunk.page_content} \\n\")"
   ],
   "id": "8d3c33a449a9b680",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 1345 chunks\n",
      "Original number of documents: 400\n",
      "Resulting number of chunks: 1345\n",
      "Showing 2 example chunks:\n",
      "\n",
      "--- Chunk 0 ---\n",
      " Elections to Liverpool City Council were held on 1 May 1975.  One third of the council was up for election. The terms of office of the Councillors elected in 1973 with the third highest number of \n",
      "\n",
      "--- Chunk 1 ---\n",
      " elected in 1973 with the third highest number of votes in each ward, expired and so these election results were compared with the 1973 results. Bill Smyth of the Liberal Party became the Leader of \n",
      "\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create FAISS vector store from chunks",
   "id": "707d61dd576a5173"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T10:56:53.420699Z",
     "start_time": "2025-11-13T10:56:47.969745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vector_store = FAISS.from_documents(chunks, embeddings)\n",
    "print(\"FAISS vector store created.\")"
   ],
   "id": "d93fd916d6a9d067",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS vector store created.\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Task 2: Manually retrieve relevant chunks for a query\n",
    "Look through your wikipedia articles and pick a topic you remember seeing. Formulate a query about that topic and use the vector store to retrieve relevant chunks. Print out the retrieved chunks to see if they are relevant to your query."
   ],
   "id": "fb48c889b3027f1e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T11:11:12.320453Z",
     "start_time": "2025-11-13T11:11:12.219182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# score_threshold = 1.3\n",
    "results = vector_store.similarity_search_with_score(\"...\", k=3)\n",
    "print(f\"Retrieved {len(results)} results. Showing excerpts:\\n\")\n",
    "for i, (doc, score) in enumerate(results):\n",
    "    print(f\"--- Result {i} (score: {score}) url: {doc.metadata['article_url']} ---\\n {doc.page_content[:500]} \\n\")"
   ],
   "id": "26d6fe9b9e4ba9c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 results. Showing excerpts:\n",
      "\n",
      "--- Result 0 (score: 1.5495978593826294) url: https://en.wikipedia.org/?curid=49537660 ---\n",
      " KK FMP. However, not only according to the club's official website, but also according to the official website of the Adriatic League, this club still competes in the Adriatic League. \n",
      "\n",
      "--- Result 1 (score: 1.5620182752609253) url: https://en.wikipedia.org/?curid=36493000 ---\n",
      " Departments: \n",
      "\n",
      "--- Result 2 (score: 1.567713737487793) url: https://en.wikipedia.org/?curid=774551 ---\n",
      " In a conversation with Space.com contributor Michael Paine, SCAP head Jin Zhu said that the program's allotted time to use the Schmidt telescope was significantly reduced to make room for the \n",
      "\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Task 3: Manually generate answer with LLM\n",
    "Effectively complete the RAG pipeline.\n",
    "In previous cell we retrieved relevant chunks for a query. Now, use those chunks as context to generate an answer with the LLM.\n",
    "This is the last part of RAG pipeline."
   ],
   "id": "534b26e1d528d652"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-13T11:03:23.495588Z",
     "start_time": "2025-11-13T11:03:23.489963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = llm\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Use the provided context to answer the user's question. If unsure, say you don't know.\"),\n",
    "    (\"human\", \"Question: {question}\\n\\nContext:\\n{context}\\n\\nAnswer:\")\n",
    "])\n",
    "\n",
    "context = \"\\n\\n\".join(f\"{d.metadata['article_url']}: \\n {d.page_content}\" for d, _ in results)\n",
    "\n",
    "## YOUR CODE HERE\n",
    "# query = prompt.format_prompt(...)\n",
    "# response = llm.invoke(...)\n",
    "\n",
    "..."
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Now lets use built-in tools to create a RAG chain",
   "id": "e1d6803f2a04eb8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T11:09:56.964720Z",
     "start_time": "2025-11-13T11:09:56.952519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(d.page_content for d in docs)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Use the provided context to answer the user's question. If unsure, say you don't know.\"),\n",
    "    (\"human\", \"Question: {question}\\n\\nContext:\\n{context}\\n\\nAnswer:\")\n",
    "])\n",
    "\n",
    "#  \"score_threshold\": 1.3\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"RAG chain constructed.\")"
   ],
   "id": "cc8ea73f098caede",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG chain constructed.\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T11:10:16.013821Z",
     "start_time": "2025-11-13T11:10:10.625779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question = \"...\"\n",
    "answer = rag_chain.invoke(question)\n",
    "print(\"Question:\\n\", question)\n",
    "print(\"\\nAnswer:\\n\", answer)"
   ],
   "id": "b7d33b78d26c752",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      " Wasps\n",
      "\n",
      "Answer:\n",
      " Chiloe micropteron is a species of wasp in the family Baeomorphidae, described from Chile. Belonocnema kinseyi is a gall wasp species that forms galls on oak trees (Quercus virginiana and Quercus fusiformis) and has both asexual and sexual generations.\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4ebfa5761dedea0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Persistence for vector store\n",
    "PERSIST_DIR = \"faiss_index\"\n",
    "os.makedirs(PERSIST_DIR, exist_ok=True)\n",
    "vector_store.save_local(PERSIST_DIR)\n",
    "print(f\"Saved FAISS index to {PERSIST_DIR}\")\n"
   ],
   "id": "7ccbc29d80ff59bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "reloaded = FAISS.load_local(PERSIST_DIR, embeddings, allow_dangerous_deserialization=True)\n",
    "print(\"Reloaded store size:\", len(reloaded.index_to_docstore_id))"
   ],
   "id": "d0b4ebd2b6281f68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b55a5867eab66a26"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Home Assignment:\n",
    "1. Complete the tasks marked as \"YOUR CODE HERE\" in the notebook.\n",
    "2. Find a dataset of your choice (e.g. book reviews, product descriptions, news articles, wine reviews, cooking recipes, etc.)\n",
    "3. It is proposed to search for datasets on websites like Kaggle, UCI Machine Learning Repository, Huggingface, or other open data sources, but you may scrape data from websites as well, however it is harder. In case of scraping, make use of tools like BeautifulSoup, Scrapy, or Selenium to extract the data.\n",
    "4. download and load the dataset into LangChain documents\n",
    "5. split the documents into chunks\n",
    "6. create a FAISS vector store from the chunks\n",
    "7. create a RAG chain using the vector store and an LLM of your choice\n",
    "8. test the RAG chain with some queries relevant to your dataset\n",
    "9. Include instructions as to how to run your code and reproduce your results. Where to download dataset from, how to set up environment variables, etc.\n",
    "10. Reuse the above examples and code as much as possible.\n",
    "11. You may use LLMs to assist you in writing code, but make sure to understand and be able to explain everything you submit.\n",
    "12. Submit your completed notebook along with any additional files required to run it to your google drive folder.\n",
    "13. Deadline: Next Monday (17.11.25) 23:59\n",
    "\n",
    "\n",
    "## !!! The budget for Azure OpenAI usage is limited. Be mindful of the number of tokens you use to run embeddings. try not to exceed 5 million tokens in a single run !!!"
   ],
   "id": "ca16a8f6de31d94b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b0dd6541df7e5b41"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM Course Kernel",
   "language": "python",
   "name": "llm_course_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
